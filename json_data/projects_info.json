{
    "projects": [
      {
        "id": "ReSecure",
        "title": "ReSecure",
        "subtitle": "Innovating Home Security with Old Smartphones",
        "introduction": "In the age of rapidly advancing technology, old smartphones are often discarded or forgotten. However, ReSecure offers a novel approach by repurposing these devices into effective home surveillance cameras. By pairing an old smartphone with a companion app, ReSecure provides an affordable, accessible home security solution, negating the need for additional hardware.",
        "background": "As traditional security solutions for homes can be costly and complex, there is an increasing demand for affordable alternatives. The idea for ReSecure was born from the desire to transform unused smartphones into functional security cameras, making home security more accessible while promoting sustainability.",
        "features": [
          "Flutter Cross-Platform Development: ReSecure uses Flutter for developing the mobile app, ensuring consistent user experience across both Android and iOS.",
          "Firebase Real-Time Data Handling: The system integrates with Firebase for secure video streaming, notifications, and user management.",
          "Motion Detection and Notifications: The system includes motion detection, providing real-time alerts and minimizing false alarms.",
          "User-Friendly Interface: ReSecure is designed with usability in mind, making the setup and operation simple for even non-technical users.",
          "Multi-User Access: Allows multiple users to manage and monitor the system, increasing its flexibility for households."
        ],
        "tech_stack": "ReSecure was developed using Flutter for mobile app development, Firebase for backend services, including real-time notifications and data handling, and Google Firebase for authentication. The project is built for both Android and iOS platforms, ensuring a seamless experience across devices.",
        "development": "The project followed the Agile development methodology, breaking the process into several phases:\n\n1. Planning: Detailed analysis of requirements and tools.\n2. Design: Prototyping the app’s user interface and defining backend architecture.\n3. Development: Building and integrating motion detection, user management, and real-time notifications.\n4. Testing: Rigorous unit and system testing, followed by user feedback for refinements.\n5. Deployment: The apps were deployed on the Google Play Store and Apple App Store.",
        "challenges": "The primary challenge was achieving a balance between real-time performance and accuracy in motion detection. Using Firebase for real-time notifications and video streaming, the team also had to ensure security and low-latency performance, especially in older devices.",
        "results": "ReSecure has demonstrated its effectiveness by transforming unused smartphones into home security systems, reducing the need for costly hardware. The system provides real-time video streaming and motion detection alerts with an easy-to-use interface. User feedback shows a significant reduction in manual monitoring time, with early adopters reporting increased security without the high costs associated with traditional systems.",
        "feedback": "Users have praised ReSecure’s ease of use and the practicality of utilizing old smartphones. In one case study, a user reported successfully setting up a system without any technical background, showcasing the accessibility of the solution.",
        "improvements": "Planned improvements include:\n\n1. Web Portal and Cross-Platform Access: Enabling users to access the system via a web portal, expanding its accessibility.\n2. Advanced Motion Detection: Enhancing the customization of motion detection to reduce false positives and increase accuracy.\n3. Smart Home Integration: Future versions will integrate with other smart home devices to create a comprehensive home automation system.",
        "conclusion": "ReSecure redefines home security by upcycling old smartphones and providing a cost-effective solution without compromising on functionality. With plans for further enhancements and a clear focus on user-friendliness, ReSecure is poised to revolutionize the home security market, combining sustainability with cutting-edge technology.",
        "categories": ["Android Applications"],
        "skills": ["Flutter", "Google Firebase", "Motion Detection", "Security Camera Integration", "Cross-Platform Development"],
        "image": "images/projects/ReSecure/ReSecure.jpg",
        "link": "./projects.html"
      },
      
      
      {
        "id": "MLKIDA",
        "title": "ML K.I.D.A.",
        "subtitle": "Enhancing Agricultural Efficiency with Automated Mite Detection",
        "introduction": "In the world of agriculture, early detection of crop-damaging pests like mites is critical to maintaining crop health. Traditional pest management methods rely on human observation, which is time-consuming and prone to error. ML K.I.D.A. leverages cutting-edge machine learning techniques to automate the detection of mites, ensuring timely intervention and reducing crop losses.",
        "background": "As crop yields become increasingly threatened by pests, agricultural technology needs to keep pace. The idea for ML K.I.D.A. arose from a desire to provide farmers with a smarter, more efficient solution for pest detection, one that requires minimal manual input but delivers high-accuracy results.",
        "features": [
          "YOLOv8 Object Detection: Detects mites in real-time using a state-of-the-art deep learning model, offering high accuracy even in challenging environments.",
          "Deep Sort Algorithm: Tracks mites across video frames, allowing farmers to monitor the movement and growth of infestations.",
          "Django Web Integration: The project integrates with Django to provide a web-based interface, making the system accessible from any device with an internet connection.",
          "Data Annotation with Roboflow: Ensures high-quality training data through precise image annotation and preprocessing, improving the accuracy of mite detection.",
          "Real-time Notifications: Alerts farmers when mite activity is detected, enabling prompt action and reducing the risk of crop damage."
        ],
        "tech_stack": "The project was developed using Python for its machine learning capabilities, Django for the web interface, YOLOv8 for object detection, and Deep Sort for tracking. Roboflow was employed for data preprocessing, ensuring the model was trained on high-quality images.",
        "development": "The development process began with gathering and annotating large datasets of images showing mites on various crops. The YOLOv8 model was trained using these images to ensure it could accurately identify mites under diverse conditions. Continuous iterations and optimizations were made to improve the tracking algorithm, making sure it performed well in real-time environments.",
        "challenges": "One of the most challenging aspects of the project was optimizing the tracking algorithm to work in real-time, without sacrificing accuracy. By fine-tuning the Deep Sort algorithm and adjusting frame rates, we were able to achieve both speed and precision.",
        "results": "ML K.I.D.A. successfully detects and tracks mites with an accuracy rate of 90%, providing early warnings to farmers about potential infestations. The system has reduced manual inspection times by over 50%, allowing farmers to focus on more critical tasks and ensuring a higher crop yield.",
        "feedback": "Farmers who tested ML K.I.D.A. have reported increased efficiency in pest management, with the system detecting mites faster than traditional methods. In one case study, the early detection allowed a farm to take preventative measures, saving an entire crop from mite infestation.",
        "improvements": "Future iterations of ML K.I.D.A. will include support for detecting multiple types of pests, expanded crop coverage, and an enhanced mobile interface for real-time alerts on the go.",
        "conclusion": "ML K.I.D.A. represents the future of precision agriculture, demonstrating how machine learning can streamline pest management and safeguard global food production.",
        "categories": ["Artificial Intelligence", "Web Development", "Python"],
        "skills": ["YOLOv8", "Deep Sort Algorithm", "Django", "Roboflow", "Machine Learning Model Integration"],
        "image": "images/projects/MLKIDA/MLKIDA.jpg",
        "link": "./projects.html"
      },
      
      
      {
        "id": "AdventureMinds",
        "title": "AdventureMinds",
        "subtitle": "AdventureMinds: Collaborative Travel Planning and Social Platform",
        "introduction": "AdventureMinds is a collaborative travel planning platform that allows users to create, edit, and share detailed travel itineraries while connecting with other travel enthusiasts. The platform fosters a community where travelers exchange destination tips and document shared experiences, making it easier for users to discover new destinations and plan trips together. AdventureMinds combines the convenience of itinerary management with the social aspect of shared travel.",
        "background": "AdventureMinds was developed with the goal of simplifying the travel planning process by creating a platform where users can collaborate on itineraries and share travel experiences. The platform encourages interaction between travelers, allowing users to connect based on mutual interests and discover new destinations through community input. The system was built using Django and Python, leveraging the framework's flexibility for rapid development and scalability.",
        "features": [
          "Itinerary Creation and Sharing: Users can create detailed travel itineraries, edit them, and share them with others for collaborative planning.",
          "Chat Feature: A built-in chat system allows users to communicate in real-time, discuss travel plans, and coordinate trips.",
          "Destination Tips and Reviews: Users can exchange tips and leave reviews for specific destinations, enhancing trip planning with community insights.",
          "User Profiles and Networking: The platform encourages social interaction, allowing users to connect with like-minded travelers and build a network of travel buddies."
        ],
        "tech_stack": "AdventureMinds was developed using the following technologies:\n\n1. Django for web development.\n2. Python for scripting and feature implementation.\n3. JavaScript for interactive front-end components.\n4. SQLite for database management during development, with plans for scalable databases for production.\n5. Django Channels for enabling real-time chat functionality.",
        "development": "1. Chat System: The real-time chat system was developed using Django Channels, allowing users to communicate instantly while planning their trips together.\n2. Itinerary Management: A robust itinerary creation tool was developed that allows multiple users to collaborate on travel plans, edit details, and save changes in real time.\n3. Social Integration: User profiles and travel preferences were added, allowing users to network with others and find travel companions based on shared interests.",
        "challenges": "Developing AdventureMinds involved several key challenges:\n\n1. Real-Time Communication: Implementing the chat system required real-time data processing, which was achieved using Django Channels for WebSocket communication.\n2. Collaborative Editing: Ensuring that multiple users could simultaneously edit and save itineraries without conflicts was a technical challenge that required careful database management.",
        "results": "AdventureMinds successfully combined itinerary management with social networking, allowing users to collaborate on travel plans while connecting with other enthusiasts. The chat system has been particularly effective in fostering real-time communication between users during the planning phase.",
        "feedback": "Users appreciated the ease of collaboration and the ability to share itineraries with others. The chat feature was particularly well-received, as it allowed for smooth coordination of group trips and provided a platform for exchanging tips and destination recommendations.",
        "improvements": "Future improvements to AdventureMinds include:\n\n1. Advanced Search Filters: Implementing search filters to help users find itineraries and travel buddies based on specific criteria like destination, duration, or travel type.\n2. Mobile App Development: Expanding the platform to include a mobile application, making it easier for users to plan trips on-the-go.\n3. Enhanced Review System: Adding a more robust review and rating system for destinations, hotels, and activities.",
        "conclusion": "AdventureMinds offers a unique blend of travel planning and social networking, providing a platform for travelers to create, edit, and share itineraries while connecting with others. With its collaborative features and real-time communication tools, the platform is set to transform the way people plan and experience travel.",      
        "categories": ["Web Development", "Python"],
        "skills": ["Python", "Django", "Web Development", "PyCharm", "GitHub"],
        "image": "images/projects/AdventureMinds/AdventureMinds.jpg",
        "link": "./projects.html"
      },
      
      
      {
        "id": "PlantDiseaseDetection",
        "title": "Plant Disease Detection",
        "subtitle": "AI-Powered Plant Disease Detection for Backyard Farmers",
        "introduction": "Backyard farming is a popular activity among Canadians, especially during the summer, offering the opportunity to cultivate plants in an organic and natural environment. However, the lack of experience in identifying plant diseases poses a significant challenge to amateur farmers. The Plant Disease Detection for Backyard Farmers project aims to address this issue by developing an Android application that accurately detects plant diseases using artificial intelligence, empowering novice farmers to manage their crops efficiently.",
        "background": "The idea for this project stemmed from the growing popularity of backyard farming and the need for novice farmers to access reliable tools for plant disease identification. Farmers often struggle to diagnose diseases early enough to prevent damage to their crops. By leveraging AI technology, the project aims to offer an easy-to-use mobile application that can detect plant diseases with high accuracy and provide useful insights, ensuring the health of their plants.",
        "features": [
          "ResNet-9 Model: The application uses the ResNet-9 deep learning model, known for its ability to classify images with a high accuracy rate of 99.2%.",
          "Image-Based Detection: The system analyzes images captured via the user's phone camera, providing instant results regarding plant health.",
          "User-Friendly Interface: Designed with the user in mind, the app is easy to navigate, making it suitable for non-technical users.",
          "Sustainable Farming: By identifying plant diseases early, the app helps farmers take timely action, thus promoting sustainable farming practices."
        ],
        "tech_stack": "The project was developed using ResNet-9 for image classification, with the trained model integrated into an Android application. PyTorch was used for model training, while Kaggle's PlantVillage dataset was employed for testing and validation. The Android application serves as the front-end for users to upload images and receive results.",
        "development": "1. Data Collection and Preprocessing: The dataset consists of 87,000 images of healthy and diseased crop leaves, classified into 38 categories. These images were normalized and divided into training, validation, and test sets.\n2. Model Selection: The ResNet-9 model was chosen for its ability to overcome overfitting and vanishing gradient issues, making it ideal for deep neural networks. Data augmentation techniques like shifting, flipping, and zooming were applied to improve model generalization.\n3. Training and Optimization: The training process involved the use of batch normalization and gradient descent to enhance performance. A One Cycle Learning Rate Policy was implemented to ensure efficient learning and prevent overfitting.\n 4. Android Integration: After training, the model was integrated into an Android app, allowing users to upload plant images and receive instant feedback on potential diseases.",
        "challenges": "The project encountered several challenges, including:\n\n1. Model Selection: Finding a balance between accuracy and performance required extensive research. The ResNet-9 model was ultimately selected for its high accuracy in image classification.\n2. Overfitting Issues: The initial model overfitted the data, necessitating the use of learning rate scheduling and other optimization techniques.\n3. Deployment Difficulties: Integration into the Android app posed connectivity issues, which were resolved by developing a Python API to handle image processing and model execution on a local machine with a dedicated GPU.",
        "results": "The Plant Disease Detection application achieved an accuracy rate of 99.2% in identifying various plant diseases, providing timely and accurate diagnoses to backyard farmers. By offering a reliable tool for disease detection, the project supports sustainable farming practices and empowers novice farmers to make informed decisions about their crops.",
        "feedback": "Farmers testing the prototype app reported positive outcomes, noting the ease of use and accuracy of the disease detection. The system's quick response time allowed them to address plant health issues before they escalated, improving the overall health of their crops.",
        "improvements": "Looking forward, the team plans to:\n\n1. Expand the Dataset: Incorporate more plants and diseases to increase the model's coverage and ensure relevance for a broader range of users.\n2. Enhance the Android Application: Add features that allow users to capture images directly within the app, improving convenience and real-time functionality.\n3. Personalized Recommendations: Offer suggestions for disease management based on the detected issues, helping farmers take proactive steps to protect their plants.",
        "conclusion": "The Plant Disease Detection for Backyard Farmers project showcases the potential of artificial intelligence in supporting sustainable and efficient farming practices. With its highly accurate disease detection and user-friendly interface, the application provides amateur farmers with a valuable tool for safeguarding their crops. The team's future plans for expanding the app's capabilities further emphasize the ongoing commitment to helping farmers thrive with the aid of AI-driven technology.",
        "categories": ["Artificial Intelligence", "Python"],
        "skills": ["ResNet-9 Model", "Image Processing", "Android Development", "PyTorch", "Machine Learning Model Integration"],
        "image": "images/projects/PlantDiseaseDetection/PlantDiseaseDetection.jpg",
        "link": "./projects.html"
      },
      
      
      {
        "id": "YouTubeDataAnalysis",
        "title": "YouTube Data Analysis",
        "subtitle": "Unlocking YouTube Content Trends through Country-Wise Data Analysis",
        "introduction": "YouTube stands as a global leader in video content, with millions of users from all over the world contributing to its vast and diverse platform. The YouTube Data Analysis – Country-Wise Content Trends project aims to address the need for deeper insights into regional content trends by building a comprehensive data analysis system. Through this project, marketers, content creators, and researchers can gain valuable insights into the type of content that resonates most in specific countries, using data collected from YouTube’s API and stored on Amazon Web Services (AWS) for scalable analysis.",
        "background": "The rapid growth of YouTube has made it essential for content creators, researchers, and marketers to understand the dynamics of video popularity in different regions. Existing tools, while helpful, do not offer sufficient country-specific insights, making it difficult to identify trends. This project is designed to fill that gap by building an efficient data processing system that retrieves, stores, and analyzes YouTube trending data on a country-by-country basis. The insights derived from this analysis help marketers optimize their targeting strategies and enable content creators to tailor their work for specific audiences.",
        "features": [
          "YouTube API Integration: The system fetches real-time trending data directly from YouTube for different countries using a Python-based API script.",
          "AWS Storage & Processing: Data is securely stored in AWS S3 buckets and processed using AWS Glue, Lambda, and Athena, ensuring scalability and performance.",
          "Visualization via AWS QuickSight: Data trends are visualized through interactive charts and graphs, helping users easily interpret country-wise content patterns.",
          "Automated Data Pipeline: The system automatically imports trending video data on a daily basis, ensuring that the data is up-to-date.",
          "Data Security: AWS infrastructure ensures the secure handling of sensitive data, adhering to YouTube API compliance guidelines."
        ],
        "tech_stack": "The project utilizes several key technologies:\n\n1. Python: Used for developing the script that interacts with the YouTube API and automates data collection.\n2. AWS (Amazon Web Services): S3 for data storage, Glue for data transformation, Athena for querying, and QuickSight for visualizations.\n3. YouTube API: Provides access to video metadata such as view counts, likes, dislikes, and more.",
        "development": "1. Data Collection: A Python script was developed to fetch real-time data from YouTube’s API, which is stored in an AWS S3 bucket.\n2. Data Transformation: AWS Glue and Lambda functions were used to clean and transform the raw data, converting it from CSV to Parquet format for optimized queries.\n3. Data Storage: Cleaned and processed data is stored in partitioned S3 buckets for easy querying.\n4. Data Visualization: AWS QuickSight was used to create visualizations, including charts and graphs that showcase trends such as video views, likes, and content categories by country.\n5. Security Measures: AWS security features ensure that all data is securely handled, with access control managed via IAM (Identity and Access Management).",
        "challenges": "The project encountered several challenges:\n\n1. Data Volume: Managing large volumes of YouTube data, especially with country-wise partitioning, proved challenging in terms of performance.\n2. Data Quality: Ensuring data consistency when transforming from CSV and JSON to Parquet format was difficult.\n3. Historical Data: YouTube’s API does not provide historical data, so the team had to rely on third-party sources to fill in gaps in past data.",
        "results": "The system successfully created a scalable and efficient platform for analyzing country-wise YouTube trends. The visualizations generated from AWS QuickSight allow for an intuitive understanding of content preferences in various regions. This system is particularly valuable for marketers looking to fine-tune their advertising campaigns and for content creators aiming to tailor their videos to specific audiences. By offering real-time insights, this project helps users stay ahead of emerging content trends.",
        "feedback": "Users have praised the system for its easy-to-use interface and the depth of insights it provides. Marketers found the tool particularly useful for identifying regional trends, while content creators used the data to adjust their production strategies, leading to increased engagement on their videos.",
        "improvements": "Looking ahead, the team plans to:\n\n1. Expand Analytical Capabilities: Develop a more robust web-based interface with additional features such as date-range filtering and advanced analytics for trend discovery.\n2. Historical Data: Continue to explore ways to incorporate historical data into the analysis, providing a more comprehensive view of content trends over time.\n3. Enhanced User Interface: Create a more interactive and user-friendly web interface that allows for advanced data exploration and real-time updates.",
        "conclusion": "The YouTube Data Analysis – Country-Wise Content Trends project has successfully leveraged AWS and the YouTube API to provide valuable insights into video content trends across different regions. By creating a scalable, secure, and efficient data analysis system, this project paves the way for deeper exploration into how different audiences engage with YouTube content globally. The future development of this project will bring even more advanced tools to help marketers, content creators, and researchers navigate the ever-evolving world of digital content.",
        "categories": ["AWS", "Data Analysis"],
        "skills": ["YouTube API", "Amazon Web Services", "Data Analysis", "Data Processing Pipeline", "Real-time Data Handling"],
        "image": "images/projects/YouTubeDataAnalysis/YouTubeDataAnalysis.jpg",
        "link": "./projects.html"
      },
      
      
      {
        "id": "ClientServerApplication",
        "title": "Client Server Application",
        "subtitle": "Client-Server File Management with Alternating Mirror System",
        "introduction": "The Client-Server File Management System is a project designed for efficient file retrieval and management across multiple clients and servers. By utilizing a client-server architecture, the project enables clients to request files from a server, which in turn searches for the requested files within its directory. An additional feature is the inclusion of a mirror server, which alternates with the main server to handle client requests. This project is ideal for understanding distributed systems, file retrieval protocols, and socket-based communication.",
        "background": "The project is centered around a client-server architecture where multiple clients can connect to the server to request files. The server checks its directory for the requested files and sends them back to the client. This project highlights important concepts in networking, such as socket communication, server forking for process management, and alternating between a server and its mirror for load balancing. The mirror server is a copy of the main server, allowing requests to be handled more efficiently.",
        "features": [
          "Socket-Based Communication: Clients and servers communicate using sockets, ensuring reliable file transmission.",
          "File Retrieval Commands: Clients can use various commands such as requesting files by name, size, type, or date.",
          "Alternating Mirror Server: The system alternates between the main server and a mirror server to handle client requests, providing a balanced load distribution.",
          "Multi-Client Support: Multiple clients can connect to the server concurrently, each being handled by a separate process.",
          "Directory-Wide Searches: The server searches for files within its root directory and returns them to the client, or an appropriate message if the file is not found."
        ],
        "tech_stack": "The system is developed using C programming for the client-server architecture, with the following core components:\n\n1. Server: Handles incoming requests and processes them in child processes.\n2. Mirror Server: A duplicate of the server that handles alternating requests.\n3. Client: Interacts with the user and sends requests to the server.",
        "development": "1. Server Initialization: The server and its mirror are initialized on separate machines. Each listens for client requests using sockets.\n2. Handling Requests: When a client sends a request, the server forks a child process that processes the request in a function named pclientrequest(). This function handles file searching and returning data to the client.\n3. Client Commands: The client sends commands to the server, which include file retrieval by name, size, type, or creation date. The commands are validated by the client before being sent to the server.\n4. Alternating Servers: The system alternates between the main server and its mirror to handle requests. The first four connections go to the main server, the next four to the mirror, and subsequent connections alternate between the two.\n5. File Transmission: Once the server identifies the requested files, they are sent back to the client and stored in a folder named f23project on the client machine.",
        "challenges": "Several challenges were encountered during the project:\n\n1. Socket Communication: Establishing reliable communication between the server, mirror, and multiple clients required careful management of socket connections.\n2. Concurrent Client Handling: Forking child processes for each client request while ensuring the main server continued to listen for new requests was a key challenge.\n3. Alternating Server and Mirror: Synchronizing the alternation between the main server and the mirror required maintaining a state that tracked which server should handle each connection.\n4. Command Validation: Ensuring that the client validated commands before sending them to the server to avoid invalid requests.",
        "results": "The client-server system was successfully implemented with the following outcomes:\n\n- Clients were able to request files using several commands, such as getfn for file names and getfz for file sizes.\n- The server efficiently handled multiple client connections, forking child processes to manage each client individually.\n- Alternating between the server and mirror reduced the load on a single server, leading to more efficient request handling and improved system performance.",
        "feedback": "Initial user tests demonstrated that the system effectively balanced server load, allowing multiple clients to request files simultaneously. Users appreciated the flexibility of file retrieval options and the reliability of the server in processing commands.",
        "improvements": "Planned enhancements for the project include:\n\n1. Enhanced Security: Introducing encryption for file transfers to ensure secure communication between clients and servers.\n2. File Caching: Implementing file caching mechanisms on the server to speed up repeated file requests.\n3. Dynamic Load Balancing: Further improving the alternation between the server and mirror based on dynamic factors such as server load and client demand.",
        "conclusion": "The Client-Server File Management System demonstrates the power of socket-based communication in distributed systems. By enabling multiple clients to request files from a server and its mirror, the project balances load effectively and provides a robust system for file retrieval across machines. The alternating server-mirror system further enhances the scalability of the solution, making it suitable for environments where file management across distributed networks is essential.",
        "categories": ["C Language"],
        "skills": ["Socket Programming", "Multi-Threading", "File Handling", "Process Forking", "Network Programming"],
        "image": "images/projects/ClientServerApplication/ClientServerApplication.jpg",
        "link": "./projects.html"
      },
      
      
      {
        "id": "DiabetesDiseasePrediction",
        "title": "Diabetes Disease Prediction",
        "subtitle": "Diabetes Disease Prediction using Machine Learning on Big Data of Healthcare",
        "introduction": "This review paper provides a comprehensive analysis of the study 'Diabetes Disease Prediction using Machine Learning on Big Data of Healthcare.' The essay's goal is to critically evaluate and list the benefits and drawbacks of the original work. The essay also implements the algorithms from the research article, compares several machine learning techniques, and recommends a novel strategy to address current issues. The goal of this study is to provide a complete survey that will help readers have a better grasp of diabetes prediction and its advances in the healthcare industry.",
        "background": "Millions of individuals throughout the world struggle with diabetes, a serious health issue. It is a chronic condition caused by the body's inability to make enough insulin or use it appropriately, which raises blood sugar levels. Diabetes can have harmful effects on the body's organs, such as renal failure, blindness, and heart disease. Machine learning has the potential to help address the problem of diabetes by accurately predicting the disease and providing automated diagnosis under the validation of a professional doctor.",
        "features": [
          "Machine Learning Models: Several machine learning algorithms, such as Naive Bayes, Support Vector Machine, Random Forest, and Simple CART, were implemented to create a classifier model for diabetes prediction.",
          "WEKA Tool: The WEKA tool was used for building and comparing these models, identifying Support Vector Machine as the most accurate model for predicting diabetes.",
          "Big Data in Healthcare: The study focuses on big data analysis in the healthcare sector and how machine learning can extract meaningful patterns from it.",
          "Comprehensive Comparison: A detailed comparison of various machine learning techniques for diabetes prediction was provided, evaluating their strengths and weaknesses."
        ],
        "tech_stack": "The study applied machine learning models using the WEKA tool. The implementation phase used Python, with several models developed using the Dataspell IDE for comparison. Key models included:\n\n1. Fully Connected Neural Network (CNN)\n2. Long Short-Term Memory (LSTM)\n3. K-Nearest Neighbors (KNN)\n4. Logistic Regression\n5. Support Vector Machine (SVM)\n6. Random Forest\n7. Naive Bayes\n8. Simple CART\n9. XGBoost\n10. CatBoost",
        "development": "1. Model Selection: Various machine learning models were selected for the study, including traditional models like Logistic Regression and advanced ones like CNN and LSTM.\n2. Performance Evaluation: The models were evaluated using metrics like accuracy, true positive rate (recall), false positive rate, precision, and F-Measure to compare their effectiveness.\n3. Comparison of Models: Naive Bayes showed the highest accuracy at 76.62%, while XGBoost had the lowest accuracy at 68.83%.\n4. Feature Engineering: The dataset was processed to ensure the accuracy and reliability of the machine learning models, focusing on handling big healthcare data efficiently.",
        "challenges": "Some challenges encountered during the project were:\n\n1. Data Volume: The healthcare dataset was large, and processing it with different machine learning models required optimized handling.\n2. Model Performance: While certain models like Naive Bayes and SVM performed well, others like XGBoost showed lower performance due to the nature of the dataset.\n3. Data Privacy: Managing and processing sensitive healthcare data required ensuring security and privacy throughout the experiment.",
        "results": "The models were evaluated on various performance metrics, and the results showed that:\n\n- Naive Bayes had the highest accuracy (76.62%) and F-Measure (68.42%).\n- Simple CART achieved the highest recall rate (72.73%).\n- Support Vector Machine had the lowest false positive rate (18.18%) and highest precision (66.67%).\n- XGBoost had the lowest accuracy (68.83%) and precision (55.38%).",
        "feedback": "The study demonstrated the potential of machine learning in predicting diabetes using big healthcare data. Users appreciated the comparison of models and the detailed performance evaluation, which highlighted areas where models like Naive Bayes and SVM excelled. However, there were suggestions to improve the overall accuracy by experimenting with other machine learning techniques.",
        "improvements": "Future work should focus on:\n\n1. Data Privacy Solutions: Addressing the issues of security and privacy when handling large-scale medical datasets.\n2. Exploring Advanced Models: Exploring other machine learning algorithms or methodologies to improve accuracy, such as deep learning models with more layers.\n3. Enhancing Data Quality: Improving the dataset quality and volume for better training, which can lead to more reliable predictions.",
        "conclusion": "The Diabetes Disease Prediction project provided a useful comparison of various machine learning models for healthcare data. By leveraging big data in healthcare and employing machine learning techniques, the study offers insights into improving diabetes prediction models. However, future research is needed to refine these models and address challenges such as data privacy and the incorporation of more advanced techniques.",
        "categories": ["Artificial Intelligence", "Python"],
        "skills": ["Machine Learning Algorithms", "Scikit-learn", "Data Preprocessing", "Random Forest", "Naive Bayes Classification"],
        "image": "images/projects/DiabetesDiseasePrediction/DiabetesDiseasePrediction.jpg",
        "link": "./projects.html"
      },
      
      
      {
        "id": "WiseBridge",
        "title": "WiseBridge",
        "subtitle": "WiseBridge: An Online Education Platform for Networking and Learning",
        "introduction": "WiseBridge is an online education platform designed to connect Master of Applied Computing (MAC) students and alumni from the University of Windsor. The platform allows experts (senior students and alumni) to post educational content and monetize it, while offering students a reliable source of course-related materials and networking opportunities.",
        "background": "Traditional education is increasingly being supplemented or replaced by online platforms. WiseBridge aims to provide students of the MAC program with focused educational content from verified experts, tailored to their specific academic needs. Additionally, it creates a networking platform for students and alumni, fostering collaboration and knowledge sharing.",
        "features": [
          "Content Upload and Monetization: Experts can upload course materials, including notes, videos, and audio files, and monetize their content.",
          "Student Access: Students have access to verified educational resources, including course content uploaded by experts, and can download materials for offline use.",
          "Networking Platform: WiseBridge facilitates collaboration through chat groups and offline event scheduling, allowing students and alumni to network effectively.",
          "Content Moderation: All content is subject to review and approval by the platform admin, ensuring that only high-quality, relevant materials are made available to students.",
          "User Roles: Three user types exist within the platform—Students, Experts, and Admins—each with distinct privileges and responsibilities."
        ],
        "tech_stack": "The development of WiseBridge uses the following technologies:\n\n1. Java for core programming.\n2. Android Studio for building the Android application.\n3. Firebase for cloud-based database and authentication services.\n4. GitHub for version control.\n5. Jira for project management.",
        "development": "1. Provisional Project Planning: The project was divided into four sprints, each with specific tasks, such as setting up repositories, implementing user roles, designing and developing UI, and testing the platform.\n2. Sprint Reports: Regular sprints were conducted to monitor progress, with adjustments made for unforeseen challenges like team familiarity with the tech stack.\n3. Class Diagrams and Use Case Design: Initial designs for user interactions and class structures were refined as the project progressed, resulting in a final system architecture for managing users, content, and subscriptions.",
        "challenges": "Several challenges were encountered during the development:\n\n1. Team Familiarity: The development team was relatively new to Android development, leading to delays as members learned the necessary tools and technologies.\n2. Time Constraints: Modifications in sprint planning were required to accommodate training sessions and project adjustments.\n3. Content Moderation: Scaling the content moderation process presented challenges as the application grew, potentially requiring more manpower to review and approve materials.",
        "results": "WiseBridge successfully provided a platform for students and experts to engage in educational content sharing and networking. The app's review and approval system ensured that students received quality materials, while the monetization feature allowed experts to earn supplemental income. Despite early challenges, the project was completed within the set timeline.",
        "feedback": "Students and experts praised WiseBridge for its targeted approach to networking and learning. The user-friendly interface and monetization feature were particularly appreciated by the experts. Some feedback suggested improving the scalability of the content moderation process as the platform grows.",
        "improvements": "Future iterations of WiseBridge will focus on:\n\n1. Scalability: Improving the content moderation system to handle a larger number of users and content submissions.\n2. Enhanced Features: Introducing a seminar or event organization feature to allow experts to schedule meetings with students.\n3. Improved Networking: Expanding the networking capabilities to include broader collaboration tools beyond chat and event scheduling.",
        "conclusion": "WiseBridge offers a niche-focused educational platform for MAC students and alumni, providing a unique combination of content sharing, networking, and monetization. By fostering collaboration and providing valuable resources, WiseBridge stands out as a tailored solution for the academic community at the University of Windsor.",      
        "categories": ["Android Applications"],
        "skills": ["Java", "Firebase", "Android Studio", "Scrum Methodology", "GitHub"],
        "image": "images/projects/WiseBridge/WiseBridge.jpg",
        "link": "./projects.html"
      },
      
      
      {
        "id": "TradeManager",
        "title": "Trade Manager",
        "subtitle": "Trade Manager: Automating Multi-Account Trading",
        "introduction": "The Trade Manager is a desktop application designed to streamline the process of managing multiple trading accounts across different brokers. This software allows users to execute the same trades in multiple accounts simultaneously, making it easier for traders to manage their portfolios. By automating trades based on pre-defined strategies, the application simplifies the trading process, reduces time, and minimizes manual errors.",
        "background": "In the fast-paced world of stock trading, managing multiple accounts across different brokers can be time-consuming and prone to error. Trade Manager was developed to address this issue by providing a unified platform for executing trades. It also allows for automatic order execution based on trading strategies selected by the user, ensuring that trades are placed consistently and accurately.",
        "features": [
          "Multi-Account Trading: Execute trades in multiple broker accounts from a single platform.",
          "Automated Strategies: Users can select pre-defined trading strategies that automatically execute orders.",
          "Trade History: The application provides a consolidated view of trading history across all accounts, with options to filter data.",
          "Open/Close Positions: View open and close positions across multiple accounts in one place, simplifying portfolio management.",
          "Net P/L Calculation: The system calculates net profit/loss and commissions for all accounts on a weekly basis."
        ],
        "tech_stack": "The Trade Manager project was built using the following technologies:\n\n1. Python for front-end and back-end development.\n2. PyCharm as the development environment.\n3. MongoDB for database management.\n4. WebSockets for real-time communication with brokers.\n5. InstallForge for creating the software installer.\n6. Watchdog library for monitoring real-time data changes.",
        "development": "1. System Architecture: The software connects multiple trading accounts to a single interface, providing a consolidated view of trade history and open positions.\n2. Automation: The project implements algorithmic trading, allowing the system to place trades automatically according to selected strategies.\n3. Testing: Rigorous testing was conducted to ensure accuracy in order execution and data handling across multiple accounts.",
        "challenges": "Some challenges encountered during the development process include:\n\n1. Multi-Account Management: Developing a system that manages multiple accounts while ensuring accurate synchronization was complex.\n2. Real-Time Data Processing: Handling real-time data from brokers required optimizing performance to ensure timely execution of trades.\n3. Security: Ensuring secure handling of sensitive user credentials and trading data was a top priority.",
        "results": "The Trade Manager successfully achieved its goal of simplifying multi-account trading. It allows users to automate trades, manage open and close positions, and view trading history for all accounts in one place. The automated strategies have proven effective in saving time and reducing manual errors.",
        "feedback": "User feedback has been positive, with traders appreciating the convenience of managing multiple accounts from one platform. The automation features were particularly well-received, as they allowed users to focus on strategy rather than execution.",
        "improvements": "Future improvements include:\n\n1. Adding support for more brokers to expand the reach of the platform.\n2. Enhancing security features, such as two-factor authentication, to improve data safety.\n3. Further optimizing the performance of real-time data processing to ensure even faster execution times.",
        "conclusion": "The Trade Manager provides a robust solution for traders managing multiple accounts, combining automation, efficiency, and ease of use into one platform. As trading continues to evolve, the system offers traders an edge by simplifying and automating their trading processes.",      
        "categories": ["Python", "Algo Trading"],
        "skills": ["Python Programming", "MongoDB", "Data Analysis", "PyQt5", "Multithreading"],
        "image": "images/projects/TradeManager/TradeManager.jpg",
        "link": "./projects.html"
      },
      
      
      {
        "id": "TradeCopy",
        "title": "Trade Copy",
        "subtitle": "Trade Copy: A Background Service for Odin Users",
        "introduction": "The Trade Copy software is designed to complement the Trade Manager by automating the process of copying trades from Odin software to the Trade Manager. Running as a background service, Trade Copy ensures that signals generated in Odin are immediately captured and executed in the Trade Manager, facilitating seamless integration between the two systems.",
        "background": "Odin users often face challenges in copying trades across platforms. Trade Copy was developed to address this issue by automatically reading trades from Odin and sending them to the Trade Manager for execution. The software runs continuously in the background, ensuring that all trades are captured and executed in real-time without any manual intervention.",
        "features": [
          "Automatic Trade Copying: Captures trades from Odin software and sends them to the Trade Manager for execution.",
          "Background Service: Runs automatically on startup and operates in the background, ensuring uninterrupted service.",
          "Real-Time Execution: Ensures that trades are copied and executed in real-time, without delay."
        ],
        "tech_stack": "Trade Copy was developed using the following technologies:\n\n1. Python for back-end development.\n2. Watchdog library for monitoring file changes in Odin directories.\n3. WebSocket for real-time communication with the Trade Manager.\n4. PyInstaller for creating the executable file.",
        "development": "1. System Architecture: Trade Copy monitors Odin directories for changes using the Watchdog library and sends captured trade signals to the Trade Manager via WebSocket.\n2. Real-Time Monitoring: The software continuously monitors Odin files, capturing and sending new trade signals immediately.\n3. Testing: Extensive testing ensured that the system worked seamlessly with the Trade Manager and executed trades without delay.",
        "challenges": "Some challenges faced during development include:\n\n1. Real-Time Monitoring: Ensuring that the software accurately captured trade signals in real-time required optimizing the monitoring process.\n2. Integration with Odin: Seamless integration with Odin's file system was necessary to ensure the system worked as intended.",
        "results": "Trade Copy successfully automates the process of copying trades from Odin to the Trade Manager. Users have reported seamless integration, with trades being executed in real-time without manual intervention.",
        "feedback": "Users appreciated the automation provided by Trade Copy, as it reduced the need for manual trade copying and ensured that trades were executed quickly and accurately.",
        "improvements": "Future improvements for Trade Copy include:\n\n1. Expanding support for additional trading platforms beyond Odin.\n2. Enhancing the robustness of the file monitoring system to handle larger volumes of trade signals.",
        "conclusion": "Trade Copy is a valuable addition to the Trade Manager system, providing users with seamless, real-time integration between Odin and Trade Manager. Its background operation ensures that users can focus on trading without worrying about manual trade copying.",
        "categories": ["Python", "Algo Trading"],
        "skills": ["WebSocket", "Algo Trading", "REST API", "Python Scripting", "Risk Management"],
        "image": "images/projects/TradeCopy/TradeCopy.jpg",
        "link": "./projects.html"
      },
      
      
      {
        "id": "TradeMaster",
        "title": "Trade Master",
        "subtitle": "Trade Master: Back-End Trade Execution System for AlgoSuccess",
        "introduction": "Trade Master is a back-end trade execution system developed for AlgoSuccess, a leading platform for algorithmic trading. The system allows traders to execute orders automatically through brokerage APIs, ensuring real-time trade placement. Designed for high-frequency traders, Trade Master integrates seamlessly with AlgoSuccess’s algorithmic strategies, providing a reliable and efficient solution for automated trading.",
        "background": "With the increasing demand for algorithmic trading solutions, Trade Master was created to enable seamless trade execution within the AlgoSuccess platform. The system was designed to handle high volumes of orders while ensuring low-latency communication with brokers. This back-end infrastructure supports traders by automating their strategies, allowing them to focus on refining algorithms without worrying about manual execution.",
        "features": [
          "Real-Time Trade Execution: The system executes trades in real-time, ensuring timely order placement and updates.",
          "Brokerage API Integration: Trade Master is integrated with multiple brokerage APIs, allowing traders to manage accounts and place trades from a single platform.",
          "High-Volume Order Handling: Built for high-frequency trading, Trade Master can handle large volumes of trades without compromising performance.",
          "Error Handling & Risk Management: The system includes mechanisms to handle errors and ensure risk management, preventing excessive losses due to market fluctuations."
        ],
        "tech_stack": "The development of Trade Master uses the following technologies:\n\n1. Python for back-end development.\n2. WebSocket for real-time communication with broker APIs.\n3. MongoDB for storing trade histories and logs.\n4. AWS services for cloud deployment and scalability.",
        "development": "1. API Integration: The system integrates with brokerage APIs using WebSocket connections to ensure real-time trade execution and updates.\n2. Error Handling: Various error-handling mechanisms were implemented to manage failed orders or broker disconnections, ensuring that traders faced minimal disruptions.\n3. Trade Validation: Each trade is validated against predefined conditions to ensure compliance with risk management rules.",
        "challenges": "Developing Trade Master involved several challenges:\n\n1. Low-Latency Execution: Ensuring that trades were executed in real-time required optimizing the system for low-latency communication with brokers.\n2. High-Volume Handling: Managing a large number of trades simultaneously without delays or performance bottlenecks was a key challenge.\n3. API Reliability: The system had to handle intermittent broker API issues and ensure that trades were executed reliably even during connection disruptions.",
        "results": "Trade Master successfully executed high-volume trades with low latency, providing users of AlgoSuccess with a seamless trading experience. It handled real-time communication with multiple brokers while minimizing downtime and errors.",
        "feedback": "Users of the AlgoSuccess platform praised the speed and reliability of Trade Master. The automated execution of trades allowed traders to focus on strategy rather than manual trade placement, enhancing overall trading performance.",
        "improvements": "Future improvements for Trade Master include:\n\n1. Expanding to More Brokers: Adding support for more brokerage APIs to increase the flexibility of the system.\n2. Enhanced Risk Management: Improving the risk management features to provide more customizable risk profiles for traders.\n3. Optimizing Latency: Further reducing trade execution time to ensure even faster order placement.",
        "conclusion": "Trade Master has proven to be a reliable back-end trade execution system, enabling AlgoSuccess users to trade automatically and efficiently. By integrating with multiple brokers and handling high-frequency trades, it provides traders with the tools they need to succeed in the fast-paced world of algorithmic trading.",      
        "categories": ["Python", "Algo Trading"],
        "skills": ["Algo Trading", "WebSocket", "Asynchronous Programming", "Multithreading", "REST API"],
        "image": "images/projects/TradeMaster/TradeMaster.jpg",
        "link": "./projects.html"
      },
      
      
      {
        "id": "HedgeStrategy",
        "title": "Hedge Strategy",
        "subtitle": "HedgeStrategy: Risk Mitigation for Bank Nifty Index Using Python",
        "introduction": "HedgeStrategy is a Python-based trading system developed to implement hedging strategies for the Bank Nifty index on the National Stock Exchange of India. The system was designed to minimize potential losses by taking strategic positions in options and futures based on live price movements. Using a combination of live data from broker APIs and historical price analysis, the system automates hedge strategies to optimize risk management for traders.",
        "background": "The stock market is inherently volatile, and traders often use hedging strategies to mitigate risk. HedgeStrategy was developed to provide a solution for traders focusing on the Bank Nifty index. The system takes advantage of options and futures contracts to reduce downside risk while still allowing traders to participate in upward price movements. By fetching live price data and storing historical data in MongoDB, the strategy enables real-time decision-making and risk management.",
        "features": [
          "Live Price Fetching: HedgeStrategy uses a broker’s WebSocket connection to fetch live price data for the Bank Nifty index and its related derivatives.",
          "Automated Risk Management: The system automatically executes hedging strategies to mitigate risk, including buying protective options or futures contracts.",
          "Data Storage and Analysis: MongoDB is used to store historical price data, enabling the system to analyze trends and make informed hedging decisions.",
          "Python Scripting: The strategy is fully scripted in Python, allowing for flexibility in adjusting and optimizing the hedging algorithms."
        ],
        "tech_stack": "The development of HedgeStrategy utilized the following technologies:\n\n1. Python for scripting and implementing the hedging algorithms.\n2. WebSocket for real-time price fetching from the broker’s API.\n3. MongoDB for storing historical price data and trade information.\n4. Pandas and NumPy for data processing and analysis.",
        "development": "1. WebSocket Integration: The system connects to the broker’s WebSocket API to fetch live price updates for Bank Nifty and its associated options and futures.\n2. Data Storage: MongoDB stores historical price data, which is used for trend analysis and executing hedging decisions based on predefined strategies.\n3. Python Scripting: Custom Python scripts implement the core hedging logic, including options buying and selling based on live price movement and historical data.",
        "challenges": "Developing HedgeStrategy posed several challenges:\n\n1. Real-Time Data Processing: Ensuring that live data from the WebSocket API was processed quickly enough for real-time decision-making.\n2. Strategy Optimization: Balancing between effective hedging and profit potential required fine-tuning the algorithm to optimize risk versus reward.",
        "results": "HedgeStrategy successfully automated hedging for Bank Nifty trades, reducing downside risk while allowing traders to maintain profit potential in volatile market conditions. The system’s live data fetching and historical analysis allowed for accurate and timely execution of hedging strategies.",
        "feedback": "Users of HedgeStrategy appreciated the ease of automation and the effectiveness of the hedging strategies in reducing risk during volatile market conditions. The system's real-time responsiveness and ability to handle large datasets were particularly praised.",
        "improvements": "Future improvements to HedgeStrategy include:\n\n1. Support for Additional Indices: Expanding the system to include hedging strategies for other indices like Nifty50 and Sensex.\n2. Enhanced Strategy Customization: Allowing users to adjust and customize their hedging strategies based on their risk appetite.\n3. More Advanced Analytics: Integrating more sophisticated trend analysis and machine learning techniques for improved decision-making.",
        "conclusion": "HedgeStrategy provides an effective, Python-based solution for hedging trades in the Bank Nifty index. By leveraging live data and automated decision-making, the system helps traders mitigate risk in volatile market environments, making it an essential tool for modern algorithmic traders.",
        "categories": ["Python", "Algo Trading"],
        "skills": ["Algo Trading", "WebSocket", "Asynchronous Programming", "Multithreading", "REST API"],
        "image": "images/projects/HedgeStrategy/HedgeStrategy.jpg",
        "link": "./projects.html"
      },
      
      
      {
        "id": "PlacementPackagePrediction",
        "title": "Placement Package Prediction",
        "subtitle": "Placement Package Prediction System: A Machine Learning Approach",
        "introduction": "The Placement Package Prediction System is a machine learning-based model designed to predict the placement package a student will receive during campus placements. By using previous years' student placement data, the system provides a predictive model that takes into account a student's academic performance, achievements, project work, and extracurricular activities. This model is integrated into an Android application, allowing students to input their data and receive an estimated package prediction.",
        "background": "Placements are a key metric of success for colleges, with students making admissions decisions based on an institution's placement records. The project aims to support this process by providing an analysis and prediction model for placement packages, based on historical data. By using machine learning techniques, the system can provide students with insights into their expected package based on a variety of factors, including CGPA, projects, and more. The algorithms are trained using data from the past two years of student placements.",
        "features": [
          "Android Integration: The machine learning model is integrated into an Android application, allowing students to input data and receive predictions on-the-go.",
          "Machine Learning Model: The model is trained on previous placement data using supervised learning techniques to predict a student's package.",
          "Predictive Insights: Based on student academic performance, projects, and activities, the system provides a predicted package amount.",
          "User-Friendly Interface: Students can easily input their details and obtain predictions using an intuitive interface designed for accessibility."
        ],
        "tech_stack": "The Placement Package Prediction System uses the following technologies:\n\n1. Python for building the machine learning model.\n2. Jupyter Notebook for developing and testing the machine learning algorithms.\n3. Android Studio for creating the mobile application.\n4. NumPy, Pandas, and Scikit-learn for data processing and machine learning.\n5. Matplotlib for visualizing results and performance of the model.",
        "development": "1. Data Gathering: The placement data from the past two years, comprising over 100 instances of student records, was collected from the placement department of the college.\n2. Pre-Processing: Data pre-processing involved cleaning the dataset, handling missing values using the Imputer class from Scikit-learn, and selecting relevant attributes such as CGPA, backlogs, project work, and placement status.\n3. Model Training: The dataset was split into training and test sets, with 80% used for training and 20% for testing. Feature scaling was applied to ensure consistent results across different attributes.\n4. Algorithm Selection: Various algorithms were tested, including Random Forest and Ensemble Learning techniques (boosting and bagging). The Random Forest Classifier provided the best results for the placement package prediction.",
        "challenges": "Several challenges were faced during the development process:\n\n1. Data Quality: Handling missing and incomplete data was a key challenge, as it required careful cleaning and preprocessing to ensure accurate model training.\n2. Model Accuracy: Ensuring that the machine learning model produced reliable predictions involved testing different algorithms and fine-tuning hyperparameters for better results.\n3. Integration: Integrating the machine learning model into the Android application required seamless communication between the front-end and back-end to ensure user inputs were processed efficiently.",
        "results": "The Placement Package Prediction System successfully predicts the package a student is likely to receive during campus placements, providing an estimated figure based on historical data. The system achieved satisfactory accuracy using the Random Forest Classifier, and its predictions were found to be useful for students preparing for placements.",
        "feedback": "Users of the system appreciated the ease of use provided by the Android application, as well as the insights offered by the predictive model. The system gave students a clear idea of their potential placement outcomes, allowing them to plan and prepare accordingly.",
        "improvements": "Future improvements for the project include:\n\n1. Enhancing Data Accuracy: By incorporating additional factors such as internship experience, extracurricular achievements, and soft skills, the prediction accuracy can be improved.\n2. Expanding the Dataset: Increasing the size of the dataset by including more years of placement records would result in better model training and more reliable predictions.\n3. Real-Time Feedback: Integrating a feedback loop that allows students to update their profiles in real-time and get updated predictions would improve the system's usability.",
        "conclusion": "The Placement Package Prediction System provides a useful tool for students preparing for campus placements. By leveraging machine learning, the system offers predictive insights based on historical placement data, giving students an idea of their expected package. The integration of this system into an Android application makes it accessible and user-friendly, though future enhancements can further improve its accuracy and features.",
        "categories": ["Artificial Intelligence", "Android Applications", "Python"],
        "skills": ["Random Forest", "Data Preprocessing", "NumPy, Pandas, Scikit-learn", "Keras", "Tkinter"],
        "image": "images/projects/PlacementPackagePrediction/PlacementPackagePrediction.jpg",
        "link": "./projects.html"
      }


    ]
  }
  